{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6c50f01a-72fd-4804-9f54-d77b52d3991f",
      "metadata": {
        "id": "6c50f01a-72fd-4804-9f54-d77b52d3991f"
      },
      "source": [
        "# [모의 캐글-의료] 흉부 CT 코로나 감염 여부 분류\n",
        "- 이미지 binary 분류 과제\n",
        "- 담당: 이녕민M"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f51ba7c1-0393-47ec-89d9-f6f97072773b",
      "metadata": {
        "id": "f51ba7c1-0393-47ec-89d9-f6f97072773b"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4325d39-6344-4116-b343-df51696905ec",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4325d39-6344-4116-b343-df51696905ec",
        "outputId": "00e84dbf-7bb3-4ea6-92b9-34e5d989856d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.88.152)] [1 InRelease 14.2 kB/88.7\r                                                                               \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.88.152)] [1 InRelease 43.1 kB/88.7\r0% [Connecting to archive.ubuntu.com (91.189.88.152)] [1 InRelease 83.7 kB/88.7\r0% [Connecting to archive.ubuntu.com (91.189.88.152)] [Connecting to ppa.launch\r0% [2 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.152)\r                                                                               \rIgn:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers] [Wait\r                                                                               \rGet:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Ign:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [696 B]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:13 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:14 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [21.1 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,557 kB]\n",
            "Get:16 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,466 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [781 kB]\n",
            "Get:19 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,825 kB]\n",
            "Get:21 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [917 kB]\n",
            "Get:22 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [935 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [814 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,995 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [29.0 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,244 kB]\n",
            "Get:27 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [42.8 kB]\n",
            "Fetched 14.9 MB in 4s (4,141 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following packages were automatically installed and are no longer required:\n",
            "  cuda-command-line-tools-10-0 cuda-command-line-tools-10-1\n",
            "  cuda-command-line-tools-11-0 cuda-compiler-10-0 cuda-compiler-10-1\n",
            "  cuda-compiler-11-0 cuda-cuobjdump-10-0 cuda-cuobjdump-10-1\n",
            "  cuda-cuobjdump-11-0 cuda-cupti-10-0 cuda-cupti-10-1 cuda-cupti-11-0\n",
            "  cuda-cupti-dev-11-0 cuda-documentation-10-0 cuda-documentation-10-1\n",
            "  cuda-documentation-11-0 cuda-documentation-11-1 cuda-gdb-10-0 cuda-gdb-10-1\n",
            "  cuda-gdb-11-0 cuda-gpu-library-advisor-10-0 cuda-gpu-library-advisor-10-1\n",
            "  cuda-libraries-10-0 cuda-libraries-10-1 cuda-libraries-11-0\n",
            "  cuda-memcheck-10-0 cuda-memcheck-10-1 cuda-memcheck-11-0 cuda-nsight-10-0\n",
            "  cuda-nsight-10-1 cuda-nsight-11-0 cuda-nsight-11-1 cuda-nsight-compute-10-0\n",
            "  cuda-nsight-compute-10-1 cuda-nsight-compute-11-0 cuda-nsight-compute-11-1\n",
            "  cuda-nsight-systems-10-1 cuda-nsight-systems-11-0 cuda-nsight-systems-11-1\n",
            "  cuda-nvcc-10-0 cuda-nvcc-10-1 cuda-nvcc-11-0 cuda-nvdisasm-10-0\n",
            "  cuda-nvdisasm-10-1 cuda-nvdisasm-11-0 cuda-nvml-dev-10-0 cuda-nvml-dev-10-1\n",
            "  cuda-nvml-dev-11-0 cuda-nvprof-10-0 cuda-nvprof-10-1 cuda-nvprof-11-0\n",
            "  cuda-nvprune-10-0 cuda-nvprune-10-1 cuda-nvprune-11-0 cuda-nvtx-10-0\n",
            "  cuda-nvtx-10-1 cuda-nvtx-11-0 cuda-nvvp-10-0 cuda-nvvp-10-1 cuda-nvvp-11-0\n",
            "  cuda-nvvp-11-1 cuda-samples-10-0 cuda-samples-10-1 cuda-samples-11-0\n",
            "  cuda-samples-11-1 cuda-sanitizer-11-0 cuda-sanitizer-api-10-1\n",
            "  cuda-toolkit-10-0 cuda-toolkit-10-1 cuda-toolkit-11-0 cuda-toolkit-11-1\n",
            "  cuda-tools-10-0 cuda-tools-10-1 cuda-tools-11-0 cuda-tools-11-1\n",
            "  cuda-visual-tools-10-0 cuda-visual-tools-10-1 cuda-visual-tools-11-0\n",
            "  cuda-visual-tools-11-1 default-jre dkms freeglut3 freeglut3-dev\n",
            "  keyboard-configuration libargon2-0 libcap2 libcryptsetup12\n",
            "  libdevmapper1.02.1 libfontenc1 libidn11 libip4tc0 libjansson4\n",
            "  libnvidia-cfg1-510 libnvidia-common-460 libnvidia-common-510\n",
            "  libnvidia-extra-510 libnvidia-fbc1-510 libnvidia-gl-510 libpam-systemd\n",
            "  libpolkit-agent-1-0 libpolkit-backend-1-0 libpolkit-gobject-1-0 libxfont2\n",
            "  libxi-dev libxkbfile1 libxmu-dev libxmu-headers libxnvctrl0 libxtst6\n",
            "  nsight-compute-2020.2.1 nsight-compute-2022.1.0 nsight-systems-2020.3.2\n",
            "  nsight-systems-2020.3.4 nsight-systems-2021.5.2 nvidia-dkms-510\n",
            "  nvidia-kernel-common-510 nvidia-kernel-source-510 nvidia-modprobe\n",
            "  nvidia-settings openjdk-11-jre policykit-1 policykit-1-gnome python3-xkit\n",
            "  screen-resolution-extra systemd systemd-sysv udev x11-xkb-utils\n",
            "  xserver-common xserver-xorg-core-hwe-18.04 xserver-xorg-video-nvidia-510\n",
            "Use 'apt autoremove' to remove them.\n",
            "The following additional packages will be installed:\n",
            "  python3-numpy\n",
            "Suggested packages:\n",
            "  python-numpy-doc python3-nose python3-numpy-dbg\n",
            "The following NEW packages will be installed:\n",
            "  python3-numpy python3-opencv\n",
            "0 upgraded, 2 newly installed, 0 to remove and 62 not upgraded.\n",
            "Need to get 2,477 kB of archives.\n",
            "After this operation, 13.9 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 python3-numpy amd64 1:1.13.3-2ubuntu1 [1,943 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python3-opencv amd64 3.2.0+dfsg-4ubuntu0.1 [534 kB]\n",
            "Fetched 2,477 kB in 1s (3,046 kB/s)\n",
            "Selecting previously unselected package python3-numpy.\n",
            "(Reading database ... 155113 files and directories currently installed.)\n",
            "Preparing to unpack .../python3-numpy_1%3a1.13.3-2ubuntu1_amd64.deb ...\n",
            "Unpacking python3-numpy (1:1.13.3-2ubuntu1) ...\n",
            "Selecting previously unselected package python3-opencv.\n",
            "Preparing to unpack .../python3-opencv_3.2.0+dfsg-4ubuntu0.1_amd64.deb ...\n",
            "Unpacking python3-opencv (3.2.0+dfsg-4ubuntu0.1) ...\n",
            "Setting up python3-numpy (1:1.13.3-2ubuntu1) ...\n",
            "Setting up python3-opencv (3.2.0+dfsg-4ubuntu0.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ]
        }
      ],
      "source": [
        "!apt-get update && apt-get install -y python3-opencv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f475804-13db-484c-a348-f01580e80a1e",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6f475804-13db-484c-a348-f01580e80a1e",
        "outputId": "e6c2272b-71d0-4862-cba5-f62257092166"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.19.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install sklearn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9siZY8S5uRIU",
        "outputId": "0c1f7822-8db1-47f2-ba24-11ac1926117e"
      },
      "id": "9siZY8S5uRIU",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Feb 13 14:19:41 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   45C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "id": "98a45c7e-10ca-4fd1-9fd4-6326313a631a",
      "metadata": {
        "id": "98a45c7e-10ca-4fd1-9fd4-6326313a631a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c287998a-d97f-467c-b5c7-085b43be83d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import os, torch, copy, cv2, sys, random\n",
        "# from datetime import datetime, timezone, timedelta\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from pylab import rcParams\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "from google.colab.patches import cv2_imshow \n",
        "import torchvision.transforms.functional as TF\n",
        "from imgaug import augmentables\n",
        "import imgaug as ia\n",
        "import imgaug.augmenters as iaa\n",
        "import torchvision\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a6c255b-b30d-4ffd-a663-bc01a2c37954",
      "metadata": {
        "id": "3a6c255b-b30d-4ffd-a663-bc01a2c37954"
      },
      "source": [
        "## Set Arguments & hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "id": "8f9c4250-2257-404f-941d-58eff1e9eb38",
      "metadata": {
        "id": "8f9c4250-2257-404f-941d-58eff1e9eb38"
      },
      "outputs": [],
      "source": [
        "# 시드(seed) 설정\n",
        "\n",
        "RANDOM_SEED = 2022\n",
        "\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "np.random.seed(RANDOM_SEED)\n",
        "random.seed(RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LW6-uUu5xfy1"
      },
      "id": "LW6-uUu5xfy1"
    },
    {
      "cell_type": "raw",
      "id": "a9c63836-0a7a-48f7-a5ea-e16b617fec65",
      "metadata": {
        "id": "a9c63836-0a7a-48f7-a5ea-e16b617fec65"
      },
      "source": [
        "# 데이터 디렉토리 구조\n",
        "\n",
        "data/  \n",
        "  \\_train/  \n",
        "    \\_0.png  \n",
        "    \\_1.png  \n",
        "    \\_...  \n",
        "  \\_test/  \n",
        "    \\_0.png  \n",
        "    \\_1.png  \n",
        "    \\_...  \n",
        "  \\_train.csv  \n",
        "  \\_sample_submission.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "id": "9d69a8bc-2e64-4de6-928f-4e16957f6af9",
      "metadata": {
        "id": "9d69a8bc-2e64-4de6-928f-4e16957f6af9"
      },
      "outputs": [],
      "source": [
        "# parameters\n",
        "\n",
        "### 데이터 디렉토리 설정 ###\n",
        "DATA_DIR= '/content/drive/MyDrive/이어드림/project2/data'\n",
        "NUM_CLS = 2\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 0.0005\n",
        "EARLY_STOPPING_PATIENCE = 20\n",
        "INPUT_SHAPE = 128\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
        "DEVICE = torch.device('cuda')\n",
        "DATA_SIZE = 1000\n",
        "TRAIN_PER = 0.85"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d44807b0-7788-49ec-aff2-c756e4513c5e",
      "metadata": {
        "id": "d44807b0-7788-49ec-aff2-c756e4513c5e"
      },
      "source": [
        "## Dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5b81fa5-3756-46aa-b3cb-6f19879aba05",
      "metadata": {
        "id": "a5b81fa5-3756-46aa-b3cb-6f19879aba05"
      },
      "source": [
        "#### Train & Validation Set loader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip -uq '/content/drive/MyDrive/이어드림/project2/test.zip' -d '/content/drive/MyDrive/이어드림/project2'\n",
        "# !unzip -uq '/content/drive/MyDrive/이어드림/project2/train.zip' -d '/content/drive/MyDrive/이어드림/project2'\n"
      ],
      "metadata": {
        "id": "g4dXCoAUlrZH"
      },
      "id": "g4dXCoAUlrZH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "A6It9wEWWPx0"
      },
      "id": "A6It9wEWWPx0"
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "id": "04642777-c2e0-439b-9692-f6c571a86521",
      "metadata": {
        "id": "04642777-c2e0-439b-9692-f6c571a86521"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data_dir, mode, input_shape, data_size, train_per):\n",
        "        self.data_dir = data_dir\n",
        "        self.mode = mode\n",
        "        self.input_shape = input_shape\n",
        "        self.data_size = data_size\n",
        "        self.train_per = train_per\n",
        "        # Loading dataset\n",
        "        self.db = self.data_loader()\n",
        "        \n",
        "        # Dataset split\n",
        "        if self.mode == 'train':\n",
        "            self.db = self.db[:int((self.data_size) * (self.train_per))]\n",
        "        elif self.mode == 'val':\n",
        "            self.db = self.db[int((self.data_size) * (self.train_per)):int(self.data_size)]\n",
        "            self.db.reset_index(inplace=True)\n",
        "        else:\n",
        "            print(f'!!! Invalid split {self.mode}... !!!')\n",
        "            \n",
        "        # Transform function\n",
        "        self.transform = transforms.Compose([transforms.Resize(self.input_shape),\n",
        "                                             transforms.ToTensor(),\n",
        "                                             transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "    def data_loader(self):\n",
        "        print('Loading ' + self.mode + ' dataset..')\n",
        "        if not os.path.isdir(self.data_dir):\n",
        "            print(f'!!! Cannot find {self.data_dir}... !!!')\n",
        "            sys.exit()\n",
        "        \n",
        "        # (COVID : 1, No : 0)\n",
        "        db = pd.read_csv(os.path.join(self.data_dir, 'train.csv'))\n",
        "        def dbplus(db):\n",
        "            augdb = db.copy()\n",
        "            for i in range(51):\n",
        "                if i == 0:\n",
        "                    augdb['file_name'] = db['file_name'].apply(lambda x : int(x[:-4]) + int('646'))\n",
        "                    augdb['file_name'] = augdb['file_name'].apply(lambda x : str(x) +'.png')\n",
        "                    db = pd.concat([db, augdb], ignore_index = True,axis=0)\n",
        "                else :\n",
        "                    augdb['file_name'] = augdb['file_name'].apply(lambda x : int(x[:-4]) + int('646'))\n",
        "                    augdb['file_name'] = augdb['file_name'].apply(lambda x : str(x) +'.png')\n",
        "                    db = pd.concat([db, augdb], ignore_index = True,axis=0)\n",
        "            return db\n",
        "        return dbplus(db)\n",
        "        \n",
        "    def __len__(self):\n",
        "        if self.mode == 'train':\n",
        "            return int((int(self.data_size))*(self.train_per))\n",
        "        elif self.mode == 'val':\n",
        "            return int((int(self.data_size)) - int((int(self.data_size))*(self.train_per)))\n",
        "    def __getitem__(self, index):\n",
        "        data = copy.deepcopy(self.db.loc[index])\n",
        "        # Loading image\n",
        "        cvimg = cv2.imread(os.path.join(self.data_dir,'train',data['file_name']), cv2.IMREAD_COLOR | cv2.IMREAD_IGNORE_ORIENTATION)\n",
        "        if not isinstance(cvimg, np.ndarray):\n",
        "            raise IOError(\"Fail to read %s\" % data['file_name'])\n",
        "\n",
        "        # Preprocessing images\n",
        "        trans_image = self.transform(Image.fromarray(cvimg))\n",
        "         \n",
        "        return trans_image, data['COVID']\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#augment시 사용\n",
        "eq_img_list = []\n",
        "class Augmentation:\n",
        "    def __init__(self, data_dir, mode, input_shape):\n",
        "        self.data_dir = data_dir\n",
        "        self.mode = mode\n",
        "        self.input_shape = input_shape\n",
        "        self.img = None\n",
        "    \n",
        "        #이미지크기 저장공간\n",
        "\n",
        "        self.db = self.data_loader()\n",
        "        if self.mode == 'train':\n",
        "            self.db = self.db[:int(len(self.db) * 0.9)]\n",
        "        elif self.mode == 'val':\n",
        "            self.db = self.db[int(len(self.db) * 0.9):]\n",
        "            self.db.reset_index(inplace=True)\n",
        "        else:\n",
        "            print(f'!!! Invalid split {self.mode}... !!!')\n",
        "            \n",
        "        # Transform function\n",
        "        self.transform = transforms.Compose([transforms.Resize(self.input_shape),\n",
        "                                             transforms.ToTensor(),\n",
        "                                             transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "    def data_loader(self):\n",
        "        print('Loading ' + self.mode + ' dataset..')\n",
        "        if not os.path.isdir(self.data_dir):\n",
        "            print(f'!!! Cannot find {self.data_dir}... !!!')\n",
        "            sys.exit()\n",
        "        \n",
        "        # (COVID : 1, No : 0)\n",
        "        db = pd.read_csv(os.path.join(self.data_dir, 'train.csv'))\n",
        "       \n",
        "        return db\n",
        "    def Equalization(self):\n",
        "    #    // for cnt in tqdm(range(646)):\n",
        "        for i in tqdm(range(646)):\n",
        "            # img = eq_img_list\n",
        "            db = pd.read_csv(os.path.join(self.data_dir, 'train.csv'))\n",
        "            data = copy.deepcopy(db.loc[i])\n",
        "            cvimg = cv2.imread(os.path.join(self.data_dir,'train',data['file_name']))\n",
        "            cvimg_yuv = cv2.cvtColor(cvimg, cv2.COLOR_BGR2YUV)\n",
        "\n",
        "            img_clahe = cvimg_yuv.copy()\n",
        "            clahe = cv2.createCLAHE(clipLimit = 3.0 , tileGridSize=(8,8))\n",
        "            img_clahe[:,:,0] = clahe.apply(img_clahe[:,:,0])\n",
        "            img_clahe = cv2.cvtColor(img_clahe, cv2.COLOR_YUV2BGR)\n",
        "\n",
        "                # img_eq = cv2_imshow(img_clahe)\n",
        "            # cv2.waitKey()\n",
        "            cv2.destroyAllWindows()\n",
        "            eq_img_list.append(img_clahe)\n",
        "            # os.makedirs('/content/drive/MyDrive/이어드림/project2/data/aug_img', exist_ok=True)\n",
        "            cv2.imwrite(f'/content/drive/MyDrive/이어드림/project2/data/train/{i}.png', img_clahe)\n",
        "            self.img = eq_img_list\n",
        "        return eq_img_list\n",
        "\n",
        "    def augmentation(self):\n",
        "        \n",
        "        for i in tqdm(range(646)):\n",
        "            \n",
        "            db = pd.read_csv(os.path.join(self.data_dir, 'train.csv'))\n",
        "            data = copy.deepcopy(db.loc[i])\n",
        "            sss =cv2.imread(os.path.join(self.data_dir,'train',data['file_name']))\n",
        "            \n",
        "            # cv2_imshow(sss)\n",
        "            augmentation_resize = iaa.Sequential([\n",
        "                            iaa.Resize({\"height\":384,\"width\":384},interpolation=\"cubic\")\n",
        "                        ])\n",
        "\n",
        "\n",
        "            image_aug = augmentation_resize(image=sss)\n",
        "            # cv2_imshow(image_aug)\n",
        "            # sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
        "            for j in (range(10)):\n",
        "                augmentation_resize = iaa.Sequential([\n",
        "                                    # iaa.Affine(translate_percent={\"x\":(-0.5,0.5),\"y\":(-0.5,0.5)},rotate=(-2,2),scale=(0.5,2)),\n",
        "                                    # iaa.Crop(px=(0, 16)),\n",
        "                                    # iaa.Multiply((0.8, 1.3)),\n",
        "                                    iaa.LinearContrast((0.75,1.45)),\n",
        "                                    iaa.GaussianBlur((0.0,1.5)),\n",
        "                                    iaa.Fliplr(0.5),\n",
        "                                    iaa.Flipud(0.3),\n",
        "                                    # iaa.Affine(translate_px={\"x\": (-20, 20), \"y\": (-20, 20)}),\n",
        "                                    # iaa.PerspectiveTransform(scale=(0.01, 0.15)),\n",
        "                                    # iaa.PiecewiseAffine(scale=(0.01, 0.05)),\n",
        "                                    iaa.Sharpen(alpha=(0, 0.3), lightness=(0.75, 1.00)),\n",
        "                                    # iaa.Emboss(alpha=(0, 1.0), strength=(0, 1.5)),\n",
        "                                     \n",
        "                                    ])\n",
        " \n",
        "                image_augs = augmentation_resize(image=image_aug)\n",
        "            # cv2_imshow(image_augs)\n",
        "                # os.makedirs('/content/drive/MyDrive/이어드림/project2/data/augment{}'.format(j), exist_ok=True)\n",
        "                #cv2.imwrite(f'/content/drive/MyDrive/이어드림/project2/data/train/{(i)+(1292)+(646*j)}.png', image_augs)\n",
        "                cv2.imwrite(f'/content/drive/MyDrive/이어드림/project2/data/train/{(i)+(646)+(646*j)}.png', image_augs)\n"
      ],
      "metadata": {
        "id": "SJjYJ-LjGXCF"
      },
      "id": "SJjYJ-LjGXCF",
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data augm\n",
        "if __name__ == '__main__': \n",
        "    temp = Augmentation(DATA_DIR,'train', INPUT_SHAPE)\n",
        "    print('이미w지를 불러오는 중입니다.')\n",
        "    temp.data_loader()\n",
        "    print('*' * 30)\n",
        "    print('Equalization중 입니다')\n",
        "    # temp.Equalization()\n",
        "    print('*' * 30)\n",
        "    print('Equalization 성공')\n",
        "    print('Augmentation중 입니다')\n",
        "    temp.augmentation()\n",
        "    print('*' * 30)\n",
        "    del temp\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pyn67QEKHalG",
        "outputId": "a44c609b-c1af-4621-b9e0-bd405bbcd07f"
      },
      "id": "Pyn67QEKHalG",
      "execution_count": 108,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading train dataset..\n",
            "이미w지를 불러오는 중입니다.\n",
            "Loading train dataset..\n",
            "******************************\n",
            "Equalization중 입니다\n",
            "******************************\n",
            "Equalization 성공\n",
            "Augmentation중 입니다\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 646/646 [51:27<00:00,  4.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "******************************\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61b27520-c82c-4ec8-ae0b-119a79167f09",
      "metadata": {
        "id": "61b27520-c82c-4ec8-ae0b-119a79167f09"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "685e0b73-f323-40ea-b372-6c1d607618a9",
      "metadata": {
        "id": "685e0b73-f323-40ea-b372-6c1d607618a9"
      },
      "outputs": [],
      "source": [
        "# import torch.nn.functional as F\n",
        "\n",
        "# class custom_CNN(nn.Module):\n",
        "#     def __init__(self, num_classes):\n",
        "#         super(custom_CNN, self).__init__()\n",
        "#         self.conv1 = nn.Conv2d(in_channels=3, out_channels=8, kernel_size=5)\n",
        "#         self.bn1 = nn.BatchNorm2d(8)\n",
        "#         self.conv2 = nn.Conv2d(in_channels=8, out_channels=25, kernel_size=5)\n",
        "#         self.bn2 = nn.BatchNorm2d(25)\n",
        "#         self.pool = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "#         self.fc1 = nn.Linear(in_features=25*29*29, out_features=128)\n",
        "#         self.fc2 = nn.Linear(in_features=128, out_features=num_classes)\n",
        "\n",
        "#         self.softmax = nn.Softmax(dim=1)\n",
        "        \n",
        "#     def forward(self, x):\n",
        "#         x = self.pool(F.relu(self.conv1(x))) # (32, 3, 128, 128) -> (32, 8, 62, 62)\n",
        "#         x = self.pool(F.relu(self.conv2(x))) # (32, 8, 62, 62) -> (32, 25, 29, 29)\n",
        "        \n",
        "#         x = torch.flatten(x,1)\n",
        "#         x = self.conv\n",
        "#         x = F.relu(self.fc1(x))\n",
        "#         x = F.relu(self.fc2(x))\n",
        "\n",
        "#         output = self.softmax(x)\n",
        "        \n",
        "#         return output\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class custom_CNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(custom_CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=12, kernel_size=5, stride=1, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(12)\n",
        "        self.conv2 = nn.Conv2d(in_channels=12, out_channels=12, kernel_size=5, stride=1, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(12)\n",
        "        self.pool = nn.MaxPool2d(2,2)\n",
        "        self.conv4 = nn.Conv2d(in_channels=12, out_channels=24, kernel_size=5, stride=1, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(24)\n",
        "        self.conv5 = nn.Conv2d(in_channels=24, out_channels=24, kernel_size=5, stride=1, padding=1)\n",
        "        self.bn5 = nn.BatchNorm2d(24)\n",
        "        self.fc1 = nn.Linear(864, 128)\n",
        "        self.fc2 = nn.Linear(in_features=128, out_features=num_classes)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "        self.dropout = F.dropout(p=0.3)\n",
        "    def forward(self, input):\n",
        "        output = F.relu(self.bn1(self.conv1(input)))  \n",
        "        output = self.pool(output)    \n",
        "        output = F.relu(self.bn2(self.conv2(output)))     \n",
        "        output = self.pool(output)                        \n",
        "        output = F.relu(self.bn4(self.conv4(output)))     \n",
        "        output = self.pool(output)\n",
        "        output = F.relu(self.bn5(self.conv5(output)))    \n",
        "        output = self.pool(output) \n",
        "        # output = output.view(-1, 24*10*10)/\n",
        "        output = torch.flatten(output,1)\n",
        "        output = self.fc1(output)\n",
        "        \n",
        "        output = self.fc2(output)\n",
        "        output = self.softmax(output)\n",
        "\n",
        "        return output\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class custom_CNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(custom_CNN, self).__init__()\n",
        "        self.layer1=nn.Sequential(\n",
        "                        nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3),\n",
        "                        nn.ReLU(),\n",
        "                        nn.MaxPool2d(kernel_size=2,stride=2),\n",
        "                        nn.BatchNorm2d(32)\n",
        "                    )\n",
        "        \n",
        "        self.layer2=nn.Sequential(\n",
        "                        nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3),\n",
        "                        nn.ReLU(),\n",
        "                        nn.MaxPool2d(kernel_size=2,stride=2),\n",
        "                        nn.BatchNorm2d(32)\n",
        "                    )\n",
        "        \n",
        "        self.layer3=nn.Sequential(\n",
        "                        nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\n",
        "                        nn.ReLU(),\n",
        "                        nn.MaxPool2d(kernel_size=2,stride=2),\n",
        "                        nn.BatchNorm2d(64)\n",
        "                    )\n",
        "        \n",
        "        self.layer4=nn.Sequential(\n",
        "                        nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3),\n",
        "                        nn.ReLU(),\n",
        "                        nn.MaxPool2d(kernel_size=2,stride=2),\n",
        "                        nn.BatchNorm2d(64)\n",
        "                    )\n",
        "        \n",
        "        self.fc1 = nn.Sequential(\n",
        "                        nn.Linear(in_features=64*14*14, out_features=64*14),\n",
        "                        nn.Dropout(p=0.3)\n",
        "                    )\n",
        "        self.fc2 = nn.Sequential(\n",
        "                        nn.Linear(in_features=64*14, out_features=128),\n",
        "                        nn.Dropout(p=0.3)\n",
        "                    )\n",
        "        self.fc3 = nn.Sequential(\n",
        "                        nn.Linear(in_features=128, out_features=num_classes),\n",
        "                        nn.Dropout(p=0.3)\n",
        "                    )\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        \n",
        "        # print(x.shape)\n",
        "        x = torch.flatten(x,1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        \n",
        "        output = self.softmax(x)\n",
        "        # print(output)\n",
        "        return output\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    x=torch.randn(5,3,128,128)\n",
        "    model=custom_CNN(2)\n",
        "\n",
        "    y=model(x)\n",
        "    print(y)\n",
        "    print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAlhwaYZa-0f",
        "outputId": "4a71733d-f2d1-418a-a3b3-4006dd2d1701"
      },
      "id": "qAlhwaYZa-0f",
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]], grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([5, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d056905-1f77-4579-a260-07bb1056f6db",
      "metadata": {
        "id": "1d056905-1f77-4579-a260-07bb1056f6db"
      },
      "source": [
        "## Utils\n",
        "### EarlyStopper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "id": "1b4c3315-ebca-4e6b-a8f2-1281ccd0bb87",
      "metadata": {
        "id": "1b4c3315-ebca-4e6b-a8f2-1281ccd0bb87"
      },
      "outputs": [],
      "source": [
        "class LossEarlyStopper():\n",
        "\n",
        "\n",
        "    def __init__(self, patience: int)-> None:\n",
        "        self.patience = patience\n",
        "\n",
        "        self.patience_counter = 0\n",
        "        self.min_loss = np.Inf\n",
        "        self.stop = False\n",
        "        self.save_model = False\n",
        "\n",
        "    def check_early_stopping(self, loss: float)-> None:\n",
        "        \"\"\"Early stopping 여부 판단\"\"\"  \n",
        "\n",
        "        if self.min_loss == np.Inf:\n",
        "            self.min_loss = loss\n",
        "            return None\n",
        "\n",
        "        elif loss > self.min_loss:\n",
        "            self.patience_counter += 1\n",
        "            msg = f\"Early stopping counter {self.patience_counter}/{self.patience}\"\n",
        "\n",
        "            if self.patience_counter == self.patience:\n",
        "                self.stop = True\n",
        "                \n",
        "        elif loss <= self.min_loss:\n",
        "            self.patience_counter = 0\n",
        "            self.save_model = True\n",
        "            msg = f\"Validation loss decreased {self.min_loss} -> {loss}\"\n",
        "            self.min_loss = loss\n",
        "        \n",
        "        print(msg)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1aaffd8d-b025-42c1-8dd8-69529487389e",
      "metadata": {
        "id": "1aaffd8d-b025-42c1-8dd8-69529487389e"
      },
      "source": [
        "### Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "id": "5faaac1b-64c3-4659-82de-d4309502f29a",
      "metadata": {
        "id": "5faaac1b-64c3-4659-82de-d4309502f29a"
      },
      "outputs": [],
      "source": [
        "class Trainer():\n",
        "\n",
        "    \n",
        "    def __init__(self, loss_fn, model, device, metric_fn, optimizer=None, scheduler=None):\n",
        "       \n",
        "    \n",
        "        self.loss_fn = loss_fn\n",
        "        self.model = model\n",
        "        self.device = device\n",
        "        self.optimizer = optimizer\n",
        "        self.scheduler = scheduler\n",
        "        self.metric_fn = metric_fn\n",
        "\n",
        "    def train_epoch(self, dataloader, epoch_index):\n",
        "        \"\"\" 한 epoch에서 수행되는 학습 절차\"\"\"\n",
        "        \n",
        "        self.model.train()\n",
        "        train_total_loss = 0\n",
        "        target_lst = []\n",
        "        pred_lst = []\n",
        "        prob_lst = []\n",
        "\n",
        "        for batch_index, (img, label) in enumerate(dataloader):\n",
        "            img = img.to(self.device)\n",
        "            label = label.to(self.device).float()\n",
        "            \n",
        "            pred = self.model(img)\n",
        "            \n",
        "            loss = self.loss_fn(pred[:,1], label)\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            self.scheduler.step()\n",
        "            \n",
        "            train_total_loss += loss.item()\n",
        "            prob_lst.extend(pred[:, 1].cpu().tolist())\n",
        "            target_lst.extend(label.cpu().tolist())\n",
        "            pred_lst.extend(pred.argmax(dim=1).cpu().tolist())\n",
        "        self.train_mean_loss = train_total_loss / batch_index\n",
        "        self.train_score, f1 = self.metric_fn(y_pred=pred_lst, y_answer=target_lst)\n",
        "        msg = f'Epoch {epoch_index}, Train loss: {self.train_mean_loss}, Acc: {self.train_score}, F1-Macro: {f1}'\n",
        "        print(msg)\n",
        "\n",
        "    def validate_epoch(self, dataloader, epoch_index):\n",
        "        \"\"\" 한 epoch에서 수행되는 검증 절차\n",
        "        \"\"\"\n",
        "        self.model.eval()\n",
        "        val_total_loss = 0\n",
        "        target_lst = []\n",
        "        pred_lst = []\n",
        "        prob_lst = []\n",
        "\n",
        "        for batch_index, (img, label) in enumerate(dataloader):\n",
        "            img = img.to(self.device)\n",
        "            label = label.to(self.device).float()\n",
        "            pred = self.model(img)\n",
        "            \n",
        "            loss = self.loss_fn(pred[:,1], label)\n",
        "            val_total_loss += loss.item()\n",
        "            prob_lst.extend(pred[:, 1].cpu().tolist())\n",
        "            target_lst.extend(label.cpu().tolist())\n",
        "            pred_lst.extend(pred.argmax(dim=1).cpu().tolist())\n",
        "        self.val_mean_loss = val_total_loss / batch_index\n",
        "        self.validation_score, f1 = self.metric_fn(y_pred=pred_lst, y_answer=target_lst)\n",
        "        msg = f'Epoch {epoch_index}, Val loss: {self.val_mean_loss}, Acc: {self.validation_score}, F1-Macro: {f1}'\n",
        "        print(msg)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2aca506-d168-4c9f-8eca-5cdecb122961",
      "metadata": {
        "id": "e2aca506-d168-4c9f-8eca-5cdecb122961"
      },
      "source": [
        "### Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "id": "33678d90-a254-48d5-bf09-2a817eeafea3",
      "metadata": {
        "id": "33678d90-a254-48d5-bf09-2a817eeafea3"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "def get_metric_fn(y_pred, y_answer):\n",
        "    \"\"\" 성능을 반환하는 함수\"\"\"\n",
        "    \n",
        "    assert len(y_pred) == len(y_answer), 'The size of prediction and answer are not same.'\n",
        "    accuracy = accuracy_score(y_answer, y_pred)\n",
        "    f1 = f1_score(y_answer, y_pred, average='macro')\n",
        "    return accuracy, f1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d729c079-9d85-49ce-857f-320b0c56a3a8",
      "metadata": {
        "tags": [],
        "id": "d729c079-9d85-49ce-857f-320b0c56a3a8"
      },
      "source": [
        "## Train\n",
        "### 학습을 위한 객체 선언"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b19610a4-ad7c-44a0-80cd-9734b5015100",
      "metadata": {
        "tags": [],
        "id": "b19610a4-ad7c-44a0-80cd-9734b5015100"
      },
      "source": [
        "#### Load Dataset & Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "id": "7cea68f0-dfad-47ce-a8ca-00ea01988886",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cea68f0-dfad-47ce-a8ca-00ea01988886",
        "outputId": "21f8639c-6d8b-4ed2-fb55-34650732ee28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading train dataset..\n",
            "Loading val dataset..\n",
            "Train set samples: 850 Val set samples: 150\n"
          ]
        }
      ],
      "source": [
        "# Load dataset & dataloader\n",
        "train_dataset = CustomDataset(data_dir=DATA_DIR, mode='train', input_shape=INPUT_SHAPE, data_size= DATA_SIZE, train_per = TRAIN_PER)\n",
        "validation_dataset = CustomDataset(data_dir=DATA_DIR, mode='val', input_shape=INPUT_SHAPE, data_size = DATA_SIZE, train_per = TRAIN_PER)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "validation_dataloader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "print('Train set samples:',len(train_dataset),  'Val set samples:', len(validation_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "aebWzBn1RTE7",
        "outputId": "1fa24994-957a-4a0a-e6ed-f80b4804e71e"
      },
      "id": "aebWzBn1RTE7",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-9ae94167d1c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: 'CustomDataset' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3bb8dae0-8e32-4ac0-a585-858a7095d2a4",
      "metadata": {
        "id": "3bb8dae0-8e32-4ac0-a585-858a7095d2a4"
      },
      "source": [
        "#### Load model and other utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "id": "cb4d52e1-752a-40d5-9b34-c06d3dbdd45a",
      "metadata": {
        "id": "cb4d52e1-752a-40d5-9b34-c06d3dbdd45a"
      },
      "outputs": [],
      "source": [
        "# Load Model\n",
        "model = custom_CNN(NUM_CLS).to(DEVICE)\n",
        "model.train()\n",
        "\n",
        "# # Save Initial Model\n",
        "# torch.save(model.state_dict(), 'initial.pt')\n",
        "\n",
        "# Set optimizer, scheduler, loss function, metric function\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "scheduler =  optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e5, max_lr=0.001, epochs=EPOCHS, steps_per_epoch=len(train_dataloader))\n",
        "loss_fn = nn.BCELoss()\n",
        "metric_fn = get_metric_fn\n",
        "\n",
        "\n",
        "# Set trainer\n",
        "trainer = Trainer(loss_fn, model, DEVICE, metric_fn, optimizer, scheduler)\n",
        "\n",
        "# Set earlystopper\n",
        "early_stopper = LossEarlyStopper(patience=EARLY_STOPPING_PATIENCE)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LR8fYPwETaT8",
        "outputId": "fd14361b-49bd-4d92-d63d-5fed383615e4"
      },
      "id": "LR8fYPwETaT8",
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "custom_CNN(\n",
              "  (layer1): Sequential(\n",
              "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (fc1): Sequential(\n",
              "    (0): Linear(in_features=12544, out_features=896, bias=True)\n",
              "    (1): Dropout(p=0.3, inplace=False)\n",
              "  )\n",
              "  (fc2): Sequential(\n",
              "    (0): Linear(in_features=896, out_features=128, bias=True)\n",
              "    (1): Dropout(p=0.3, inplace=False)\n",
              "  )\n",
              "  (fc3): Sequential(\n",
              "    (0): Linear(in_features=128, out_features=2, bias=True)\n",
              "    (1): Dropout(p=0.3, inplace=False)\n",
              "  )\n",
              "  (softmax): Softmax(dim=1)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "id": "9b881024-3921-4c2c-b9ec-e6b23c4f5ad2",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9b881024-3921-4c2c-b9ec-e6b23c4f5ad2",
        "outputId": "6a6594ca-b41c-4add-d345-970901eaf8c0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "custom_CNN(\n",
              "  (conv1): Conv2d(3, 8, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(8, 25, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=21025, out_features=128, bias=True)\n",
              "  (fc2): Linear(in_features=128, out_features=2, bias=True)\n",
              "  (softmax): Softmax(dim=1)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5aa8aef-b984-4133-b6b2-e1c85900f724",
      "metadata": {
        "id": "d5aa8aef-b984-4133-b6b2-e1c85900f724"
      },
      "source": [
        "### epoch 단위 학습 진행"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "id": "dcc35f70-25fc-48e1-92f8-8633b3b8be80",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcc35f70-25fc-48e1-92f8-8633b3b8be80",
        "outputId": "2a4031b2-cb3c-40e7-82ef-5064f3c0eaba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/50 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Train loss: 0.6833958786267501, Acc: 0.5952941176470589, F1-Macro: 0.590283382656264\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 1/50 [00:08<06:41,  8.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Val loss: 0.751901850104332, Acc: 0.7466666666666667, F1-Macro: 0.7311827956989247\n",
            "Epoch 1, Train loss: 0.5601236327336385, Acc: 0.7105882352941176, F1-Macro: 0.7027532638857299\n",
            "Epoch 1, Val loss: 0.6215328797698021, Acc: 0.78, F1-Macro: 0.776412665432043\n",
            "Validation loss decreased 0.751901850104332 -> 0.6215328797698021\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 2/50 [00:16<06:38,  8.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Train loss: 0.4911710631388884, Acc: 0.7329411764705882, F1-Macro: 0.7230034210046528\n",
            "Epoch 2, Val loss: 0.6342431157827377, Acc: 0.7733333333333333, F1-Macro: 0.7718733225979604\n",
            "Early stopping counter 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 3/50 [00:25<06:33,  8.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, Train loss: 0.45995818880888134, Acc: 0.7717647058823529, F1-Macro: 0.7622549019607843\n",
            "Epoch 3, Val loss: 0.6751944944262505, Acc: 0.7, F1-Macro: 0.6572037986897568\n",
            "Early stopping counter 2/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 4/50 [00:33<06:28,  8.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4, Train loss: 0.5358557678185977, Acc: 0.7376470588235294, F1-Macro: 0.7214445791542672\n",
            "Epoch 4, Val loss: 0.603260263800621, Acc: 0.8, F1-Macro: 0.7891679160419791\n",
            "Validation loss decreased 0.6215328797698021 -> 0.603260263800621\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 5/50 [00:41<06:19,  8.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5, Train loss: 0.5105406722197166, Acc: 0.7576470588235295, F1-Macro: 0.7425242330133635\n",
            "Epoch 5, Val loss: 0.6795719712972641, Acc: 0.7333333333333333, F1-Macro: 0.7106481481481481\n",
            "Early stopping counter 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 12%|█▏        | 6/50 [00:50<06:14,  8.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6, Train loss: 0.46165050795445073, Acc: 0.7670588235294118, F1-Macro: 0.7522216136953871\n",
            "Epoch 6, Val loss: 0.8837352842092514, Acc: 0.78, F1-Macro: 0.7771374544144793\n",
            "Early stopping counter 2/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 7/50 [00:59<06:04,  8.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7, Train loss: 0.4013555697523631, Acc: 0.7952941176470588, F1-Macro: 0.7856832343138676\n",
            "Epoch 7, Val loss: 0.5337767079472542, Acc: 0.8333333333333334, F1-Macro: 0.8237367802585194\n",
            "Validation loss decreased 0.603260263800621 -> 0.5337767079472542\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 16%|█▌        | 8/50 [01:07<05:55,  8.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8, Train loss: 0.33757635148671955, Acc: 0.8047058823529412, F1-Macro: 0.7953221464048648\n",
            "Epoch 8, Val loss: 0.6426285058259964, Acc: 0.82, F1-Macro: 0.8170649080807626\n",
            "Early stopping counter 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 9/50 [01:16<05:47,  8.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9, Train loss: 0.2902269850556667, Acc: 0.8247058823529412, F1-Macro: 0.8161858083542933\n",
            "Epoch 9, Val loss: 0.6055441051721573, Acc: 0.84, F1-Macro: 0.8392857142857144\n",
            "Early stopping counter 2/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 10/50 [01:24<05:38,  8.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10, Train loss: 0.24319553891053566, Acc: 0.8423529411764706, F1-Macro: 0.8361019017359672\n",
            "Epoch 10, Val loss: 0.6989610232412815, Acc: 0.8333333333333334, F1-Macro: 0.8316498316498316\n",
            "Early stopping counter 3/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 22%|██▏       | 11/50 [01:32<05:30,  8.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11, Train loss: 0.2925719160300035, Acc: 0.8364705882352941, F1-Macro: 0.8299047956338151\n",
            "Epoch 11, Val loss: 0.7772752568125725, Acc: 0.7866666666666666, F1-Macro: 0.7860581208771618\n",
            "Early stopping counter 4/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 12/50 [01:43<05:42,  9.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12, Train loss: 0.277228210407954, Acc: 0.8247058823529412, F1-Macro: 0.8167602518045463\n",
            "Epoch 12, Val loss: 0.6814424283802509, Acc: 0.84, F1-Macro: 0.8350439882697948\n",
            "Early stopping counter 5/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 26%|██▌       | 13/50 [01:51<05:26,  8.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13, Train loss: 0.250345725279588, Acc: 0.8305882352941176, F1-Macro: 0.822999635587485\n",
            "Epoch 13, Val loss: 0.7060407102108002, Acc: 0.82, F1-Macro: 0.8199919996444286\n",
            "Early stopping counter 6/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 14/50 [02:00<05:14,  8.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14, Train loss: 0.24659871911773315, Acc: 0.8458823529411764, F1-Macro: 0.8399985055989745\n",
            "Epoch 14, Val loss: 0.7296044379472733, Acc: 0.8133333333333334, F1-Macro: 0.8075513196480939\n",
            "Early stopping counter 7/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 15/50 [02:08<05:03,  8.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15, Train loss: 0.21954232540268165, Acc: 0.8694117647058823, F1-Macro: 0.8651563029245433\n",
            "Epoch 15, Val loss: 0.7861118502914906, Acc: 0.8533333333333334, F1-Macro: 0.8501090116279071\n",
            "Early stopping counter 8/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 16/50 [02:17<04:51,  8.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16, Train loss: 0.25306599931075024, Acc: 0.8564705882352941, F1-Macro: 0.8510605294604283\n",
            "Epoch 16, Val loss: 1.0720722749829292, Acc: 0.8066666666666666, F1-Macro: 0.8059681520139166\n",
            "Early stopping counter 9/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 17/50 [02:25<04:41,  8.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17, Train loss: 0.24817628528063113, Acc: 0.8458823529411764, F1-Macro: 0.8396944476836675\n",
            "Epoch 17, Val loss: 0.7081890515983105, Acc: 0.8466666666666667, F1-Macro: 0.8451178451178452\n",
            "Early stopping counter 10/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 36%|███▌      | 18/50 [02:34<04:34,  8.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18, Train loss: 0.2229007935294738, Acc: 0.86, F1-Macro: 0.8547903396456109\n",
            "Epoch 18, Val loss: 0.6629069931805134, Acc: 0.84, F1-Macro: 0.8381586045675238\n",
            "Early stopping counter 11/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 19/50 [02:42<04:25,  8.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19, Train loss: 0.2185561121083223, Acc: 0.8305882352941176, F1-Macro: 0.8220681955621715\n",
            "Epoch 19, Val loss: 0.7607921957969666, Acc: 0.8466666666666667, F1-Macro: 0.8446715591373644\n",
            "Early stopping counter 12/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 20/50 [02:50<04:15,  8.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20, Train loss: 0.21366567221971658, Acc: 0.8752941176470588, F1-Macro: 0.8713952120765748\n",
            "Epoch 20, Val loss: 0.834562823176384, Acc: 0.8533333333333334, F1-Macro: 0.8520444763271162\n",
            "Early stopping counter 13/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 21/50 [02:59<04:05,  8.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21, Train loss: 0.18897019555935493, Acc: 0.8870588235294118, F1-Macro: 0.8840012737115044\n",
            "Epoch 21, Val loss: 0.8270128220319748, Acc: 0.8533333333333334, F1-Macro: 0.8520444763271162\n",
            "Early stopping counter 14/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▍     | 22/50 [03:07<03:56,  8.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22, Train loss: 0.20121571478935388, Acc: 0.8647058823529412, F1-Macro: 0.8599271191128193\n",
            "Epoch 22, Val loss: 0.8987659364938736, Acc: 0.8533333333333334, F1-Macro: 0.8520444763271162\n",
            "Early stopping counter 15/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▌     | 23/50 [03:16<03:49,  8.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23, Train loss: 0.22184876982982343, Acc: 0.8470588235294118, F1-Macro: 0.8405290107314596\n",
            "Epoch 23, Val loss: 0.8654620721936226, Acc: 0.8533333333333334, F1-Macro: 0.8520444763271162\n",
            "Early stopping counter 16/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 24/50 [03:25<03:43,  8.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24, Train loss: 0.22586369801026124, Acc: 0.8611764705882353, F1-Macro: 0.8560769120390299\n",
            "Epoch 24, Val loss: 0.8397078067064285, Acc: 0.8533333333333334, F1-Macro: 0.8520444763271162\n",
            "Early stopping counter 17/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 25/50 [03:33<03:33,  8.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25, Train loss: 0.20113470462652352, Acc: 0.8529411764705882, F1-Macro: 0.8470366867210568\n",
            "Epoch 25, Val loss: 0.8118168488144875, Acc: 0.8466666666666667, F1-Macro: 0.8451178451178452\n",
            "Early stopping counter 18/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 26/50 [03:42<03:23,  8.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26, Train loss: 0.2154231733427598, Acc: 0.8717647058823529, F1-Macro: 0.867585919088065\n",
            "Epoch 26, Val loss: 0.8512559086084366, Acc: 0.8533333333333334, F1-Macro: 0.8516453875202301\n",
            "Early stopping counter 19/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 27/50 [03:50<03:15,  8.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27, Train loss: 0.20798907400323793, Acc: 0.8623529411764705, F1-Macro: 0.8573618905967852\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▍    | 27/50 [03:58<03:23,  8.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27, Val loss: 0.9050202406942844, Acc: 0.8533333333333334, F1-Macro: 0.8520444763271162\n",
            "Early stopping counter 20/20\n",
            "Early stopped\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "for epoch_index in tqdm(range(EPOCHS)):\n",
        "\n",
        "    trainer.train_epoch(train_dataloader, epoch_index)\n",
        "    trainer.validate_epoch(validation_dataloader, epoch_index)\n",
        "\n",
        "    # early_stopping check\n",
        "    early_stopper.check_early_stopping(loss=trainer.val_mean_loss)\n",
        "\n",
        "    if early_stopper.stop:\n",
        "        print('Early stopped')\n",
        "        break\n",
        "\n",
        "    if early_stopper.save_model:\n",
        "        check_point = {\n",
        "            'model': model.state_dict(),\n",
        "            'optimizer': optimizer.state_dict(),\n",
        "            'scheduler': scheduler.state_dict()\n",
        "        }\n",
        "        torch.save(check_point, 'best.pt')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe53514a-e83f-4795-9589-640f26cc2993",
      "metadata": {
        "id": "fe53514a-e83f-4795-9589-640f26cc2993"
      },
      "source": [
        "## Inference\n",
        "### 모델 로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "id": "6729cfde-c4b3-4d36-938e-f8bb8d8afef3",
      "metadata": {
        "id": "6729cfde-c4b3-4d36-938e-f8bb8d8afef3"
      },
      "outputs": [],
      "source": [
        "TRAINED_MODEL_PATH = 'best.pt'\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "vIdJV7VQmDub",
        "outputId": "e87bce6d-b1fb-4233-d475-10341735d19b"
      },
      "id": "vIdJV7VQmDub",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-a9a3f6a27dd2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: load_state_dict() missing 1 required positional argument: 'state_dict'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wZ8tBJ4wavx7"
      },
      "id": "wZ8tBJ4wavx7"
    },
    {
      "cell_type": "markdown",
      "id": "75bbba92-b53c-499f-b5f9-b6ac3edde331",
      "metadata": {
        "id": "75bbba92-b53c-499f-b5f9-b6ac3edde331"
      },
      "source": [
        "### Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "id": "ced90de9-50ec-4e18-9f42-5a1b493941a5",
      "metadata": {
        "id": "ced90de9-50ec-4e18-9f42-5a1b493941a5"
      },
      "outputs": [],
      "source": [
        "class TestDataset(Dataset):\n",
        "    def __init__(self, data_dir, input_shape):\n",
        "        self.data_dir = data_dir\n",
        "        self.input_shape = input_shape\n",
        "        \n",
        "        # Loading dataset\n",
        "        self.db = self.data_loader()\n",
        "        \n",
        "        # Transform function\n",
        "        self.transform = transforms.Compose([transforms.Resize(self.input_shape),\n",
        "                                             transforms.ToTensor(),\n",
        "                                             transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "    def data_loader(self):\n",
        "        print('Loading test dataset..')\n",
        "        if not os.path.isdir(self.data_dir):\n",
        "            print(f'!!! Cannot find {self.data_dir}... !!!')\n",
        "            sys.exit()\n",
        "        \n",
        "        db = pd.read_csv(os.path.join(self.data_dir, 'sample_submission.csv'))\n",
        "        return db\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.db)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        data = copy.deepcopy(self.db.loc[index])\n",
        "        \n",
        "        # Loading image\n",
        "        cvimg = cv2.imread(os.path.join(self.data_dir,'test',data['file_name']), cv2.IMREAD_COLOR | cv2.IMREAD_IGNORE_ORIENTATION)\n",
        "        if not isinstance(cvimg, np.ndarray):\n",
        "            raise IOError(\"Fail to read %s\" % data['file_name'])\n",
        "\n",
        "        # Preprocessing images\n",
        "        trans_image = self.transform(Image.fromarray(cvimg))\n",
        "\n",
        "        return trans_image, data['file_name']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "id": "cdd31a3d-08cd-48fc-87b0-137976d4d4bb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdd31a3d-08cd-48fc-87b0-137976d4d4bb",
        "outputId": "fda0f135-c937-4fab-f3e2-73226f03958c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading test dataset..\n"
          ]
        }
      ],
      "source": [
        "# Load dataset & dataloader\n",
        "test_dataset = TestDataset(data_dir=DATA_DIR, input_shape=INPUT_SHAPE)\n",
        "test_dataloader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53efd72b-172d-4e34-a1dd-65ed8c745b58",
      "metadata": {
        "id": "53efd72b-172d-4e34-a1dd-65ed8c745b58"
      },
      "source": [
        "### 추론 진행"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "id": "16a090ea-bb34-4d3d-a127-b1190e8c416c",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16a090ea-bb34-4d3d-a127-b1190e8c416c",
        "outputId": "becf7957-1b46-4ca6-9421-13dd2d64b366"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1it [00:00,  3.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[9.2367e-01, 7.6334e-02],\n",
            "        [1.6182e-01, 8.3818e-01],\n",
            "        [8.2463e-01, 1.7537e-01],\n",
            "        [1.3793e-03, 9.9862e-01],\n",
            "        [9.8489e-01, 1.5108e-02],\n",
            "        [1.8971e-06, 1.0000e+00],\n",
            "        [1.2099e-02, 9.8790e-01],\n",
            "        [9.4798e-01, 5.2017e-02],\n",
            "        [9.3026e-01, 6.9737e-02],\n",
            "        [6.1402e-10, 1.0000e+00],\n",
            "        [9.0248e-01, 9.7517e-02],\n",
            "        [9.9131e-01, 8.6939e-03],\n",
            "        [9.9576e-01, 4.2380e-03],\n",
            "        [1.0000e+00, 2.6981e-06],\n",
            "        [6.8009e-04, 9.9932e-01],\n",
            "        [9.7764e-01, 2.2357e-02],\n",
            "        [1.8303e-02, 9.8170e-01],\n",
            "        [9.6611e-01, 3.3886e-02],\n",
            "        [9.3632e-01, 6.3676e-02],\n",
            "        [6.2616e-01, 3.7384e-01],\n",
            "        [9.9922e-01, 7.8250e-04],\n",
            "        [9.9640e-01, 3.5985e-03],\n",
            "        [3.6933e-03, 9.9631e-01],\n",
            "        [9.9344e-01, 6.5628e-03],\n",
            "        [3.5843e-01, 6.4157e-01],\n",
            "        [9.9998e-01, 1.9002e-05],\n",
            "        [9.3410e-01, 6.5904e-02],\n",
            "        [3.5843e-03, 9.9642e-01],\n",
            "        [5.3519e-05, 9.9995e-01],\n",
            "        [1.2110e-04, 9.9988e-01],\n",
            "        [1.2212e-02, 9.8779e-01],\n",
            "        [3.8080e-07, 1.0000e+00]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r2it [00:00,  3.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[8.1598e-01, 1.8402e-01],\n",
            "        [1.4985e-02, 9.8502e-01],\n",
            "        [9.8757e-01, 1.2429e-02],\n",
            "        [9.4490e-01, 5.5103e-02],\n",
            "        [9.8330e-01, 1.6697e-02],\n",
            "        [1.7062e-02, 9.8294e-01],\n",
            "        [3.8219e-03, 9.9618e-01],\n",
            "        [3.1828e-03, 9.9682e-01],\n",
            "        [1.3423e-08, 1.0000e+00],\n",
            "        [4.0939e-01, 5.9061e-01],\n",
            "        [8.4563e-01, 1.5437e-01],\n",
            "        [1.4123e-04, 9.9986e-01],\n",
            "        [1.1714e-02, 9.8829e-01],\n",
            "        [1.4079e-03, 9.9859e-01],\n",
            "        [9.6711e-01, 3.2889e-02],\n",
            "        [9.9990e-01, 1.0301e-04],\n",
            "        [9.6801e-01, 3.1995e-02],\n",
            "        [1.5209e-01, 8.4791e-01],\n",
            "        [1.3517e-01, 8.6483e-01],\n",
            "        [1.0785e-06, 1.0000e+00],\n",
            "        [9.0879e-03, 9.9091e-01],\n",
            "        [9.8209e-02, 9.0179e-01],\n",
            "        [3.4521e-04, 9.9965e-01],\n",
            "        [1.1498e-01, 8.8502e-01],\n",
            "        [7.9316e-04, 9.9921e-01],\n",
            "        [1.1274e-06, 1.0000e+00],\n",
            "        [9.9999e-01, 1.0827e-05],\n",
            "        [5.8278e-01, 4.1722e-01],\n",
            "        [1.1065e-04, 9.9989e-01],\n",
            "        [9.9909e-01, 9.0724e-04],\n",
            "        [9.9993e-01, 7.1913e-05],\n",
            "        [9.9963e-01, 3.6758e-04]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "4it [00:00,  5.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[4.1111e-02, 9.5889e-01],\n",
            "        [1.0658e-08, 1.0000e+00],\n",
            "        [4.1222e-05, 9.9996e-01],\n",
            "        [9.9696e-01, 3.0388e-03],\n",
            "        [2.2490e-01, 7.7510e-01],\n",
            "        [9.3139e-01, 6.8612e-02],\n",
            "        [9.1986e-01, 8.0135e-02],\n",
            "        [9.5604e-01, 4.3964e-02],\n",
            "        [9.9849e-01, 1.5128e-03],\n",
            "        [9.9987e-01, 1.2750e-04],\n",
            "        [9.0754e-04, 9.9909e-01],\n",
            "        [9.9999e-01, 9.4578e-06],\n",
            "        [9.9986e-01, 1.4352e-04],\n",
            "        [9.9958e-01, 4.2194e-04],\n",
            "        [4.2669e-03, 9.9573e-01],\n",
            "        [9.6850e-05, 9.9990e-01],\n",
            "        [1.7342e-04, 9.9983e-01],\n",
            "        [9.8882e-01, 1.1184e-02],\n",
            "        [9.9153e-01, 8.4732e-03],\n",
            "        [1.4866e-06, 1.0000e+00],\n",
            "        [6.7741e-05, 9.9993e-01],\n",
            "        [6.7109e-01, 3.2891e-01],\n",
            "        [9.0905e-03, 9.9091e-01],\n",
            "        [9.9065e-01, 9.3492e-03],\n",
            "        [9.9351e-01, 6.4891e-03],\n",
            "        [6.8170e-04, 9.9932e-01],\n",
            "        [4.7224e-01, 5.2776e-01],\n",
            "        [9.9913e-01, 8.6691e-04],\n",
            "        [2.3909e-02, 9.7609e-01],\n",
            "        [6.3787e-05, 9.9994e-01],\n",
            "        [9.9117e-01, 8.8279e-03],\n",
            "        [8.7178e-01, 1.2822e-01]], device='cuda:0')\n",
            "tensor([[6.7038e-04, 9.9933e-01],\n",
            "        [1.9618e-03, 9.9804e-01],\n",
            "        [3.7751e-04, 9.9962e-01],\n",
            "        [6.6710e-02, 9.3329e-01]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "model.load_state_dict(torch.load(TRAINED_MODEL_PATH)['model'])\n",
        "\n",
        "# Prediction\n",
        "file_lst = []\n",
        "pred_lst = []\n",
        "prob_lst = []\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for batch_index, (img, file_num) in tqdm(enumerate(test_dataloader)):\n",
        "        img = img.to(DEVICE)\n",
        "        pred = model(img)\n",
        "        print(pred)\n",
        "        file_lst.extend(list(file_num))\n",
        "        pred_lst.extend(pred.argmax(dim=1).tolist())\n",
        "        prob_lst.extend(pred[:, 1].tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "056169d1-64a8-4b81-8daf-722b029cf2b9",
      "metadata": {
        "id": "056169d1-64a8-4b81-8daf-722b029cf2b9"
      },
      "source": [
        "### 결과 저장"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "id": "f133cd86-b87b-4f8b-ae0e-c240655ae9ff",
      "metadata": {
        "id": "f133cd86-b87b-4f8b-ae0e-c240655ae9ff"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame({'file_name':file_lst, 'COVID':pred_lst})\n",
        "# df.sort_values(by=['file_name'], inplace=True)\n",
        "df.to_csv(DATA_DIR+'/prediction(custom+1000,0.8).csv', index=False)\n",
        "#과적합줄이기"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JBVoxgKKZKKO"
      },
      "id": "JBVoxgKKZKKO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03a5b7ae-2810-42c4-9335-ae1c6b6e2746",
      "metadata": {
        "id": "03a5b7ae-2810-42c4-9335-ae1c6b6e2746"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "name": "Baseline ++ 가로의 사본",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}